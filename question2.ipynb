{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-04T19:37:56.654204Z",
     "start_time": "2023-11-04T19:37:56.548994Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import scipy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Conv2D, MaxPooling2D, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9990 images belonging to 10 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.preprocessing.image.DirectoryIterator at 0x7fb275652a90>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rescale=1/255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "image_gen.flow_from_directory(\"./train_data\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T19:26:25.826941Z",
     "start_time": "2023-11-04T19:26:23.765960Z"
    }
   },
   "id": "6303e3fdc15f3e5b"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "input_shape = (150, 150, 3)\n",
    "\n",
    "# add convolution layers\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=input_shape, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=input_shape, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=input_shape, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# add flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "# add dense layers\n",
    "model.add(Dense(128, activation=\"sigmoid\"))\n",
    "\n",
    "# add drop out layer to help reduce over fitting by randomly turning neurons off during training\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(10, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T19:26:32.566247Z",
     "start_time": "2023-11-04T19:26:32.356749Z"
    }
   },
   "id": "eb45d166ee90b2f5"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 74, 74, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 36, 36, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 34, 34, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 17, 17, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 18496)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               2367616   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2425226 (9.25 MB)\n",
      "Trainable params: 2425226 (9.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T19:26:33.978621Z",
     "start_time": "2023-11-04T19:26:33.783653Z"
    }
   },
   "id": "e1a39661cc5db722"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9990 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_img_gen = image_gen.flow_from_directory(\"./train_data\", target_size=input_shape[:2], batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T19:29:37.286299Z",
     "start_time": "2023-11-04T19:29:36.101397Z"
    }
   },
   "id": "30e418f28c3798ac"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{'1': 0,\n '10': 1,\n '2': 2,\n '3': 3,\n '4': 4,\n '5': 5,\n '6': 6,\n '7': 7,\n '8': 8,\n '9': 9}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img_gen.class_indices"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T19:29:50.321252Z",
     "start_time": "2023-11-04T19:29:50.241660Z"
    }
   },
   "id": "7c2efa754e048209"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scipy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_img_gen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m150\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Arian/data_science/quera_DS_bootcamp/projects/2/venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/Desktop/Arian/data_science/quera_DS_bootcamp/projects/2/venv/lib/python3.9/site-packages/keras/src/preprocessing/image.py:2526\u001B[0m, in \u001B[0;36mapply_affine_transform\u001B[0;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001B[0m\n\u001B[1;32m   2482\u001B[0m \u001B[38;5;129m@keras_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras.preprocessing.image.apply_affine_transform\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   2483\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_affine_transform\u001B[39m(\n\u001B[1;32m   2484\u001B[0m     x,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2496\u001B[0m     order\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   2497\u001B[0m ):\n\u001B[1;32m   2498\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Applies an affine transformation specified by the parameters given.\u001B[39;00m\n\u001B[1;32m   2499\u001B[0m \n\u001B[1;32m   2500\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2524\u001B[0m \u001B[38;5;124;03m        ImportError: if SciPy is not available.\u001B[39;00m\n\u001B[1;32m   2525\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 2526\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mscipy\u001B[49m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2527\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImage transformations require SciPy. Install SciPy.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   2529\u001B[0m     \u001B[38;5;66;03m# Input sanity checks:\u001B[39;00m\n\u001B[1;32m   2530\u001B[0m     \u001B[38;5;66;03m# 1. x must 2D image with one or more channels (i.e., a 3D tensor)\u001B[39;00m\n\u001B[1;32m   2531\u001B[0m     \u001B[38;5;66;03m# 2. channels must be either first or last dimension\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'scipy' is not defined"
     ]
    }
   ],
   "source": [
    "results = model.fit(train_img_gen, epochs=10, steps_per_epoch=150)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T19:38:02.790496Z",
     "start_time": "2023-11-04T19:38:02.601018Z"
    }
   },
   "id": "a31eabd3b0658935"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3715f2b0ce980172"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
