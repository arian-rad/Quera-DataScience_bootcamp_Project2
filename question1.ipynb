{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Conv2D, MaxPooling2D, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rescale=1/255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "image_gen.flow_from_directory(\"./train_data\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6303e3fdc15f3e5b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Custom model using CNN ###\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "input_shape = (150, 150, 3)\n",
    "\n",
    "# add convolution layers\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=input_shape, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=input_shape, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=input_shape, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# add flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "# add dense layers\n",
    "model.add(Dense(128, activation=\"sigmoid\"))\n",
    "\n",
    "# add drop out layer to help reduce over fitting by randomly turning neurons off during training\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# model summary\n",
    "model.summary()\n",
    "\n",
    "batch_size = 16\n",
    "train_img_gen = image_gen.flow_from_directory(\"./train_data\", target_size=input_shape[:2], batch_size=batch_size)\n",
    "\n",
    "# class indices\n",
    "print(train_img_gen.class_indices)\n",
    "\n",
    "# fit the model\n",
    "results = model.fit(train_img_gen, epochs=80, steps_per_epoch=600)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb45d166ee90b2f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "30e418f28c3798ac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "### VGG16 model ### \n",
    "\n",
    "# Set the image size and number of classes\n",
    "img_width, img_height = 224, 224\n",
    "num_classes = 10\n",
    "\n",
    "# Load the pre-trained VGG16 model without the top layers\n",
    "base_model = VGG16(weights='imagenet',\n",
    "                   include_top=False,\n",
    "                   input_shape=(img_width, img_height, 3))\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build a new model on top of the pre-trained VGG16 model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Set up the data generators for training and validation\n",
    "train_data_dir = './train_data'\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "# val_generator = val_datagen.flow_from_directory(\n",
    "#     val_data_dir,\n",
    "#     target_size=(img_width, img_height),\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='categorical')\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // batch_size,\n",
    "    epochs=epochs)\n",
    "    # validation_data=val_generator,\n",
    "    # validation_steps=val_generator.n // batch_size)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('image_classifier.h5')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3715f2b0ce980172"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "### ResNet50 model ### \n",
    "\n",
    "image_gen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rescale=1/255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_data_dir = './train_data'\n",
    "image_gen.flow_from_directory(train_data_dir)\n",
    "\n",
    "\n",
    "# Load the ResNet50 model without the top layer\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a new model and add the base ResNet50 model and additional layers\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "train_img_gen = image_gen.flow_from_directory(\"./train_data\", target_size=input_shape[:2], batch_size=64)\n",
    "# Train the model\n",
    "model.fit(train_img_gen, batch_size=64, epochs=10, )\n",
    "\n",
    "# Evaluate the model\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5d484e0f09f2955"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
